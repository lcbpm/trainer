# AI 面试基础题整理

## 📋 目录

- [1. 机器学习基础](#1-机器学习基础)
  - [1.1 监督学习](#11-监督学习)
  - [1.2 无监督学习](#12-无监督学习)
  - [1.3 强化学习](#13-强化学习)
  - [1.4 模型评估](#14-模型评估)
- [2. 深度学习基础](#2-深度学习基础)
  - [2.1 神经网络](#21-神经网络)
  - [2.2 卷积神经网络](#22-卷积神经网络)
  - [2.3 循环神经网络](#23-循环神经网络)
  - [2.4 Transformer](#24-transformer)
- [3. 自然语言处理](#3-自然语言处理)
- [4. 计算机视觉](#4-计算机视觉)
- [5. 大模型基础](#5-大模型基础)
- [6. 多模态生成模型](#6-多模态生成模型)
- [7. 实际应用](#7-实际应用)

---

## 1. 机器学习基础

### 1.1 监督学习

**Q: 什么是偏差和方差？**

**简单理解：**
- **偏差(Bias)**：模型的预测结果与正确结果之间的差距
- **方差(Variance)**：模型在不同数据上的预测结果的变化程度
- **权衡关系**：一般来说，偏差高方差低，或者偏差低方差高

**直观例子：**
- 高偏差：像一个不精准的射手，总是偏离目标
- 高方差：像一个不稳定的射手，每次都射在不同位置

**Q: 什么是过拟合和欠拟合？**

**简单解释：**
- **过拟合**：模型在训练数据上表现很好，但在新数据上表现很差
- **欠拟合**：模型太简单，连训练数据都学不好

**如何识别：**
- 过拟合：训练准确率高，测试准确率低
- 欠拟合：训练和测试准确率都低

**解决方法：**
- 过拟合：加数据、正则化、早停
- 欠拟合：增加模型复杂度、加特征

**Q: 常见的机器学习算法有哪些？**

**线性模型：**
- **线性回归**：用直线拟合数据
- **逻辑回归**：用于分类问题的线性模型

**树模型：**
- **决策树**：像做选择题一样分支决策
- **随机森林**：多个决策树投票决定

**其他常用算法：**
- **SVM**：找到最好的分类边界
- **朴素贝叶斯**：基于概率的分类方法
- **KNN**：看最近邻居的标签来决定

### 1.2 无监督学习

**Q: 什么是K-means聚类算法？**

**简单原理：**
1. 选择K个初始中心点
2. 把每个数据点分给最近的中心
3. 更新中心为该类所有点的平均值
4. 重复2-3步直到收敛

**优缺点：**
- 优点：简单易懂，速度快
- 缺点：需要预先指定K值，对初始值敏感

**Q: 还有哪些常见的无监督学习方法？**

**聚类方法：**
- **层次聚类**：逐步合并或分割
- **DBSCAN**：基于密度的聚类，能找到异常点

**降维方法：**
- **PCA**：主成分分析，找到数据的主要方向
- **t-SNE**：用于数据可视化

### 1.3 强化学习

**Q: 什么是强化学习？**

**基本概念：**
- **智能体(Agent)**：做决策的实体
- **环境(Environment)**：智能体所在的世界
- **状态(State)**：环境的当前情况
- **动作(Action)**：智能体可以做的事
- **奖励(Reward)**：做动作后得到的反馈

**Q-learning简单理解：**
- 目标：学习在每个状态下做什么动作最好
- 方法：不断尝试，根据奖励更新策略

### 1.4 模型评估

**Q: 常见的模型评估指标有哪些？**

**分类问题：**
- **准确率(Accuracy)**：预测正确的比例
- **精确率(Precision)**：预测为正类中真正正类的比例
- **召回率(Recall)**：真正正类中被预测为正类的比例
- **F1分数**：精确率和召回率的平衡

**回归问题：**
- **MSE(均方误差)**：预测值与真实值差的平方的平均
- **MAE(平均绝对误差)**：预测值与真实值差的绝对值的平均
- **R²(决定系数)**：模型解释数据变化的比例

**Q: 什么是交叉验证？**

**简单理解：**
- 把数据分成K份，轮流用K-1份训练，1份测试
- 目的：更全面地评估模型性能
- 常用：5折交叉验证

## 2. 深度学习基础

### 2.1 神经网络

**Q: 什么是神经网络？**

**基本概念：**
- **神经元**：最基本的计算单元，接收输入、加权求和、通过激活函数输出
- **层**：多个神经元组成一层
- **权重**：连接的强度，通过学习调整
- **偏置**：每个神经元的起始值

**工作原理：**
1. 输入数据从第一层传到最后一层（前向传播）
2. 计算预测结果与真实结果的差距（损失函数）
3. 从输出层向输入层传播误差（反向传播）
4. 根据误差调整权重和偏置（梯度下降）

**Q: 常见的激活函数有哪些？**

**主要激活函数：**
- **Sigmoid**：输出0-1之间，但容易梯度消失
- **Tanh**：输出-1到1之间，比Sigmoid好一些
- **ReLU**：简单有效，负数输出0，正数不变
- **Leaky ReLU**：解决ReLU的“死亡”问题

**各自特点：**
- ReLU最常用，计算简单效果好
- Sigmoid用于输出层的二分类
- Tanh用于隐藏层，比Sigmoid收敛快

### 2.2 卷积神经网络

**Q: 什么是卷积神经网络？**

**基本概念：**
- **卷积层**：用小窗口(卷积核)扫描图像，提取特征
- **池化层**：减小图像尺寸，保留主要信息
- **全连接层**：最后用于分类或预测

**主要参数：**
- **卷积核尺寸**：常用3x3或5x5
- **步长(Stride)**：卷积核移动的步骤
- **填充(Padding)**：在边缘加零，保持尺寸
- **通道数**：输出特征图的数量

**优势：**
- 适合处理图像数据
- 参数共享，减少计算量
- 对位置变化不敏感

### 2.3 循环神经网络

**Q: 什么是循环神经网络？**

**基本概念：**
- **序列数据**：有时间顺序的数据，如文本、语音
- **记忆能力**：能记住之前的信息
- **参数共享**：每个时间步使用相同参数

**主要类型：**
- **基础RNN**：最简单的RNN，但容易梯度消失
- **LSTM**：长短期记忆网络，解决长期依赖问题
- **GRU**：门控循环单元，比LSTM简单但效果接近

**LSTM vs GRU：**
- LSTM：3个门(遗忘门、输入门、输出门)，参数多
- GRU：2个门(重置门、更新门)，参数少、训练快

### 2.4 Transformer

**Q: 什么是Transformer？**

**核心概念：**
- **注意力机制**：能够关注输入序列中的任意位置
- **自注意力**：序列中每个元素都可以与其他元素直接交互
- **并行计算**：不像RNN需要顺序处理，可以并行

**主要组成：**
- **编码器(Encoder)**：理解输入序列
- **解码器(Decoder)**：生成输出序列
- **多头注意力**：同时关注多个方面的信息

**优势：**
- 并行计算能力强
- 长距离依赖建模能力好
- 注意力权重可解释

## 3. 自然语言处理

**Q: 什么是词向量？**

**基本概念：**
- 把文字转换成数字向量，让计算机能理解
- 相似的词在向量空间中距离较近

**常见方法：**
- **One-hot编码**：最简单，但维度高、稀疏
- **Word2Vec**：通过上下文学习词向量
- **GloVe**：结合全局统计和局部上下文
- **FastText**：考虑子词信息

**Q: 什么是注意力机制？**

**简单理解：**
- 让模型能够"专注"于输入中的重要部分
- 不同位置的信息有不同的重要性权重

**应用场景：**
- 机器翻译：对齐源语言和目标语言
- 文本摘要：找到关键句子
- 问答系统：关注相关信息

## 4. 计算机视觉

**Q: 什么是目标检测？**

**基本任务：**
- 找到图像中的物体在哪里（位置）
- 识别物体是什么（类别）

**常见算法：**
- **YOLO**："你只看一次"，速度快
- **R-CNN系列**：精度高但速度慢
- **SSD**：在速度和精度之间平衡

**Q: 什么是语义分割？**

**基本任务：**
- 给图像中每个像素分配类别标签
- 比目标检测更精细，需要像素级别的预测

**常见方法：**
- **FCN**：全卷积网络
- **U-Net**：编码器-解码器结构
- **DeepLab**：空洞卷积提高精度

## 5. 大模型基础

**Q: GPT和BERT有什么区别？**

**主要区别：**

| 特征 | GPT | BERT |
|------|-----|------|
| 架构 | 仅解码器 | 仅编码器 |
| 训练方式 | 逐个预测下一个词 | 填空（预测遮盖词） |
| 看数据方式 | 单向（从左到右） | 双向（同时看左右） |
| 擅长任务 | 文本生成 | 文本理解 |

**Q: 什么是预训练模型？**

**基本概念：**
- 先在大量数据上训练一个通用模型
- 再针对具体任务进行微调
- 好处：节省时间、提高效果

**常见流程：**
1. 预训练：在大数据集上学习通用特征
2. 微调：针对具体任务调整参数
3. 部署：在实际应用中使用

## 6. 多模态生成模型

### 6.1 文生图(Text-to-Image)

**Q: 什么是文生图模型？**

**基本概念：**
- 根据文字描述生成对应的图像
- 结合了自然语言理解和图像生成技术
- 通常基于扩散模型或GAN架构

**主流模型对比：**

| 模型 | 技术架构 | 优点 | 缺点 |
|------|--------|-----|-----|
| **DALL-E 2** | 扩散模型 + CLIP | 图像质量高，控制性好 | 生成速度慢 |
| **Midjourney** | 扩散模型 | 艺术效果出众 | 不开源，控制性有限 |
| **Stable Diffusion** | Latent Diffusion | 开源，资源要求低 | 需要调参技巧 |
| **DALL-E 3** | 改进扩散模型 | 文本理解能力强 | 成本高，访问限制 |
| **Adobe Firefly** | 扩散模型 | 商业化成熟 | 创新性相对不足 |

**技术原理：**
- **CLIP编码**：将文本转换为特征向量
- **扩散过程**：从噪声逐步生成清晰图像
- **潜在空间**：在低维空间进行扩散，提高效率

### 6.2 图生图(Image-to-Image)

**Q: 图生图有哪些应用场景？**

**主要任务类型：**
- **风格转换**：将照片转换为绘画风格
- **图像修复**：去噪、超分辨率、修复损坏
- **内容编辑**：更改图像中的特定元素
- **色彩化**：将黑白照片转为彩色

**主流模型：**

| 模型类型 | 代表模型 | 主要用途 |
|---------|--------|--------|
| **CycleGAN** | CycleGAN, DiscoGAN | 风格转换，无配对数据 |
| **Pix2Pix** | Pix2Pix, Pix2PixHD | 有配对数据的转换 |
| **ControlNet** | ControlNet + SD | 精细控制图像生成 |
| **InstructPix2Pix** | InstructPix2Pix | 文本指令引导编辑 |
| **Real-ESRGAN** | ESRGAN, Real-ESRGAN | 图像超分辨率 |

**技术特点：**
- **条件生成**：使用输入图像作为条件
- **结构保持**：保持原图的基本结构
- **细节增强**：改善图像的细节和质量

### 6.3 文生视频(Text-to-Video)

**Q: 文生视频模型的挑战有哪些？**

**技术挑战：**
- **时间一致性**：保持视频帧之间的连续性
- **运动合理性**：生成符合物理规律的运动
- **计算复杂度**：比图像生成需要更多资源
- **内容控制**：精确控制视频内容和节奏

**代表模型：**

| 模型 | 发布时间 | 特点 | 限制 |
|------|--------|-----|-----|
| **Runway Gen-2** | 2023 | 商业化成熟，质量稳定 | 时长限制，成本高 |
| **Pika Labs** | 2023 | 接近专业水准 | 数据访问限制 |
| **Stable Video** | 2023 | 开源，可定制 | 需要技术背景 |
| **Sora** | 2024 | 長视频生成，质量极高 | 未正式发布 |
| **LumaAI Dream** | 2024 | 用户友好 | 功能相对简单 |

**技术路线：**
- **扩散模型**：基于图像扩散模型扩展
- **自回归生成**：逐帧生成视频帧
- **3D感知**：结合空间理解生成视频

### 6.4 图生视频(Image-to-Video)

**Q: 图生视频的优势是什么？**

**主要优势：**
- **结构约束**：有初始帧作为参考，更容易控制
- **一致性保证**：保持视觉风格的一致性
- **精确控制**：可以精确指定起始和结束状态
- **计算效率**：比纯文生视频计算量小

**应用场景：**
- **照片动画化**：让静态照片“活起来”
- **产品展示**：产品的360度展示视频
- **艺术创作**：将艺术作品转为动态展示
- **教育内容**：将图表、图解制作成动画

**技术实现：**

| 模型 | 输入要求 | 输出特点 |
|------|--------|--------|
| **RunwayML** | 单张图片 | 4秒短视频，质量高 |
| **Stable Video Diffusion** | 图片+描述 | 开源，可定制 |
| **Pika 1.0** | 图片+提示词 | 支持不同长宽比 |
| **PixVerse** | 图片/文字 | 免费使用，质量适中 |

### 6.5 模型选择指南

**Q: 如何选择合适的生成模型？**

**选择因素对比：**

| 考虑因素 | 文生图 | 图生图 | 文生视频 | 图生视频 |
|---------|-------|-------|---------|--------|
| **创意自由度** | 高 | 中 | 高 | 中 |
| **控制精度** | 中 | 高 | 低 | 高 |
| **计算成本** | 低 | 低 | 高 | 中 |
| **生成速度** | 快 | 快 | 慢 | 中 |
| **结果可预测性** | 低 | 高 | 低 | 中 |

**实际应用建议：**

1. **初学者**：从 Stable Diffusion 或 Midjourney 开始
2. **专业用户**：选择 ComfyUI + 多种模型组合
3. **商业用途**：优先考虑 API 服务（OpenAI、Runway）
4. **研究开发**：使用开源模型进行定制

**最新发展趋势：**
- **多模态融合**：一个模型支持多种输入输出
- **实时生成**：生成速度不断提升
- **精细控制**：更精确的局部编辑能力
- **个性化定制**：根据用户偏好训练专属模型

## 7. 实际应用

**Q: 如何选择合适的算法？**

**考虑因素：**
- **数据量**：小数据用简单模型，大数据用复杂模型
- **精度要求**：高精度用复杂模型，可接受低精度用简单模型
- **速度需求**：实时应用选快速算法
- **解释性**：需要解释的选简单模型

**Q: 如何提高模型性能？**

**数据方面：**
- 收集更多、更好的数据
- 数据清洗和预处理
- 数据增强（旋转、缩放、噪声等）

**模型方面：**
- 调整超参数（学习率、正则化等）
- 尝试不同的模型架构
- 集成学习（多个模型投票）

**训练方面：**
- 使用预训练模型
- 交叉验证调参（网格搜索、随机搜索）
- 早停以防止过拟合

---

## 📚 总结

这份AI面试基础题整理从最基本的概念入手，帮助你：

**理解核心概念：**
- 机器学习的基本原理
- 深度学习的主要方法
- 常见问题和解决方案

**掌握实用技能：**
- 算法选择和应用
- 问题诊断和优化
- 项目实施经验

**面试建议：**
- 重点理解基本概念，不要死记公式
- 用自己的话解释技术原理
- 结合实际例子说明应用场景
- 对优缺点要有清楚认识

**持续学习方向：**
- 动手实践小项目
- 阅读经典论文
- 关注行业最新动态
- 参与开源项目