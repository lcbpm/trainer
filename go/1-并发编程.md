# 1. 并发编程 (Concurrency)

## 📋 目录

- [1.1 Goroutine 相关](#11-goroutine-相关)
  - [1.1.1 Goroutine 基本概念](#111-goroutine-基本概念)
  - [1.1.2 GMP 调度模型](#112-gmp-调度模型)
  - [1.1.3 工作窃取算法详解](#113-工作窃取算法详解)
  - [1.1.4 任务阻塞处理机制](#114-任务阻塞处理机制)
  - [1.1.5 Goroutine 泄漏防护](#115-goroutine-泄漏防护)
  - [1.1.6 最佳实践](#116-最佳实践)
- [1.2 Channel 相关](#12-channel-相关)
  - [Channel 底层实现原理](#channel-底层实现原理)
  - [Channel 常见应用模式](#channel-常见应用模式)
  - [面试答题思路](#面试答题思路)

---

### 1.1 Goroutine 相关

#### 1.1.1 Goroutine 基本概念

**🧠 什么是 Goroutine？**

Goroutine 是 Go 语言的轻量级线程。

**核心特点：**
- **轻量级**：初始栈空间只需 2KB，可动态增长
- **高效调度**：用户态调度，切换开销极小
- **大量并发**：可轻松创建百万级 Goroutine
- **简单语法**：使用 `go` 关键字即可创建

**简单类比：**
- **传统线程**：像一辆大卡车，创建成本高，占用资源多（几MB内存）
- **Goroutine**：像一辆自行车，创建成本低，占用资源少（只需2KB内存）

#### 1.1.2 GMP 调度模型

**🏭 GMP 调度模型**

Go 的并发调度基于 GMP 模型：

- **G (Goroutine)**：协程，代表一个并发任务
- **M (Machine)**：系统线程，真正执行代码的载体
- **P (Processor)**：逻辑处理器，管理 Goroutine 队列

**核心机制：**
1. **本地队列**：每个 P 维护自己的 Goroutine 队列
2. **全局队列**：系统级任务缓冲区，所有 P 共享
3. **工作窃取**：空闲的 P 从其他 P 偷取任务
4. **抢占调度**：防止长时间运行的 Goroutine 饿死其他任务
5. **系统调用处理**：阻塞时自动切换，保持高效

**数量关系：**
- P 数量 = GOMAXPROCS（通常等于 CPU 核心数）
- M 数量动态调整
- G 数量可以很大

**🏗️ 完整调度器架构：**

```
Go 调度器架构：
├── G (Goroutine) - 轻量级协程
├── M (Machine) - 系统线程
├── P (Processor) - 逻辑处理器
│   └── 本地队列 (Local Queue)
└── 全局队列 (Global Queue) - 系统级任务缓冲
```

**📊 队列类型对比：**

| 特性 | 本地队列 (Local Queue) | 全局队列 (Global Queue) |
|------|----------------------|---------------------|
| **数量** | 每个 P 一个 | 整个程序一个 |
| **容量** | 有限（通常 256 个） | 无限 |
| **访问方式** | 无锁（只有绑定的 M 访问） | 加锁（所有 P 可访问） |
| **优先级** | 高（优先检查） | 低（本地队列空时才检查） |
| **作用** | 高效任务调度 | 负载均衡和缓冲 |

**🔄 任务调度优先级：**

```
M 寻找任务的顺序：
1. 本地队列（无锁，最快）
    ↓
2. 全局队列（加锁，较慢）
    ↓
3. 工作窃取（随机选择其他 P）
    ↓
4. 休眠等待（没有任务时）
```

#### 1.1.3 工作窃取算法详解

**🔍 工作窃取算法详解**

工作窃取并不是每个 P 都主动监控其他 P，而是一个**被动触发**的高效机制。

**触发条件：**
1. P 的本地队列为空
2. M 当前没有正在执行的任务（即 M 空闲）
3. 全局队列也没有可用任务

**窃取策略：**
```
当 P1 的队列空了：
1. P1 不会"监控"所有其他 P
2. P1 会随机选择一个目标 P（比如 P2）
3. 检查 P2 的队列是否有任务
4. 如果有，窃取 P2 队列的一半任务
5. 如果没有，继续尝试下一个 P
```

**关键特点：**
1. **随机选择**：不是按顺序检查，而是随机选择目标 P
2. **偷一半**：成功窃取时，会拿走目标队列的一半任务
3. **有限尝试**：不会无限循环，通常最多尝试几次
4. **无锁优化**：使用原子操作，避免锁竞争

**实际效果示例：**
```
正常情况：
P1: [G1, G2, G3] ← 正在执行
P2: [G4, G5, G6] ← 正在执行

P1 队列空了：
P1: [] ← 需要任务
P2: [G4, G5, G6] ← 被选中

窃取后：
P1: [G5, G6] ← 窃取到任务
P2: [G4] ← 保留一半
```

所以工作窃取是一种**按需**、**随机**、**高效**的负载均衡机制，而不是主动监控模式。这样既保证了负载均衡，又最小化了性能开销。

#### 1.1.4 任务阻塞处理机制

**🔄 阻塞处理与工作窃取的区别**

任务阻塞时的处理机制和工作窃取是**不同**的。阻塞处理是**确定性**的，而不是随机的。

**处理策略对比：**

| 场景 | 触发条件 | 选择策略 | 目的 |
|------|----------|----------|---------|
| **工作窃取** | P 队列为空 | 随机选择其他 P | 负载均衡 |
| **阻塞处理** | Goroutine 阻塞 | 按队列顺序执行 | 保持执行连续性 |

**阻塞处理流程：**
```
Goroutine 阻塞 → M 与 P 解绑 → P 寻找空闲 M → 继续执行其他任务
```

**具体步骤：**
1. **检测阻塞**：当前 Goroutine 进入系统调用或 I/O 等待
2. **M-P 解绑**：执行阻塞任务的 M 从 P 上分离
3. **P 重新绑定**：P 会寻找或创建新的空闲 M
4. **继续调度**：P 从本地队列取下一个 Goroutine 执行

**为什么不是随机？**

阻塞处理的设计原则：
1. **保持局部性**：优先执行同一 P 队列中的任务，提高缓存命中率
2. **维护公平性**：按 FIFO 顺序执行，避免任务饥饿
3. **减少开销**：直接从本地队列取任务，无需搜索

**实际执行例子：**
```
P1 的队列状态：[G1, G2, G3, G4]

1. G1 正在 M1 上执行
2. G1 发生系统调用，M1 阻塞
3. M1 与 P1 解绑
4. P1 创建或找到空闲的 M2
5. P1 按顺序取 G2 执行（不是随机选择）
6. G2 → G3 → G4 按队列顺序执行
```

**对比总结：**

- **工作窃取**：随机选择目标 P，用于负载均衡
- **阻塞处理**：按队列顺序执行，保持执行连续性
- **设计目标不同**：一个是分散负载，一个是保持效率

**阻塞恢复机制：**

当阻塞的 Goroutine 准备好继续执行时：
1. 会被放回到原来的 P 的本地队列（如果 P 还存在）
2. 或者放入全局队列
3. 按调度策略重新分配执行

这种设计既保证了高效的任务执行，又实现了良好的负载均衡。

#### 1.1.5 Goroutine 泄漏防护

**定义：**
创建后无法正常结束的 Goroutine，会持续消耗系统资源。

**常见原因：**
1. **Channel 死锁**：发送方无接收方，或接收方无发送方
2. **无限循环**：没有退出条件的循环
3. **阻塞操作**：等待永不会完成的 I/O 操作
4. **忘记取消**：没有正确使用 context 取消机制

**检测方法：**
- 使用 `runtime.NumGoroutine()` 监控数量
- 使用 pprof 工具分析 Goroutine 堆栈
- 设置 Goroutine 数量告警阈值

#### 1.1.6 最佳实践

1. **生命周期管理**
   - 使用 context 控制 Goroutine 生命周期
   - 设置合理的超时时间
   - 确保所有 Goroutine 都有退出条件

2. **Channel 使用**
   - 选择合适的缓冲区大小
   - 遵循"谁创建谁关闭"原则
   - 使用 select 避免永久阻塞

3. **错误处理**
   - 在 Goroutine 内部处理 panic
   - 使用 recover 机制防止程序崩溃
   - 建立错误上报机制

4. **性能监控**
   - 定期监控 Goroutine 数量
   - 使用 pprof 分析性能瓶颈
   - 设置资源使用告警

### 1.2 Channel 相关

#### Channel 底层实现原理

* **本质**：环形队列 + 锁 + 等待队列。
* **发送**：
  * 队列有空 → 写入缓冲。
  * 队列满 → 当前 goroutine 挂到 send 队列。
  * 有接收者等待时 → 直接把数据交给接收者（不用进队列）。
* **接收**：
  * 队列有数据 → 取出数据。
  * 队列空 → 当前 goroutine 挂到 recv 队列。
  * 有发送者等待时 → 直接从发送者取数据。
* **关闭**：
  * 唤醒所有等待的 goroutine，接收者返回零值，发送者 panic。

👉 可以一句话总结：**Channel 用锁和等待队列保证并发安全，数据要么走缓冲队列，要么直接在 goroutine 间传递。**

在 Go 的 **channel** 底层，锁（`mutex`/原子操作）主要是用来保证 **并发安全** 的，因为多个 Goroutine 可能同时操作同一个 channel。我们可以分情况来看：

---

### 1️⃣ 对缓冲 channel（有缓冲区）

* **缓冲区读写**：

  * 当发送者写入缓冲区，或者接收者从缓冲区读取数据时，需要保证 **同一时间只有一个 Goroutine 访问缓冲区的数据结构**。
  * 锁保护了环形队列的 **head/tail 指针、容量、实际存储的数据**。
* **sendQueue / recvQueue**：

  * 当缓冲区满或者空时，Goroutine 会挂到等待队列。
  * 等待队列也是共享数据结构，需要加锁保证 **挂起和唤醒操作** 的安全。

---

### 2️⃣ 对无缓冲 channel（unbuffered channel）

对的，**无缓冲 channel（unbuffered channel）**的环形队列容量是 **0**。这意味着数据不会在 channel 内部存储，而是必须 **发送者和接收者同时准备好，才能完成一次传递**。

#### 1️⃣ 无缓冲 channel 特性

| 特性   | 说明                           |
| ---- | ---------------------------- |
| 缓冲容量 | 0                            |
| 发送操作 | 阻塞，直到有接收者准备好接收数据             |
| 接收操作 | 阻塞，直到有发送者准备好发送数据             |
| 数据流动 | **直接在发送者和接收者之间传递**，不经过缓冲区    |
| 用途   | 用于同步，保证发送和接收严格配对（Rendezvous） |

---

#### 2️⃣ 底层流程

```
发送者: ch <- v
┌─────────────────┐
│ 有没有接收者等待？ │──是──> 直接传递，发送完成
└─────────────────┘
          │ 否
          ▼
   阻塞，挂起发送者，等待接收者出现

接收者: v := <-ch
┌─────────────────┐
│ 有没有发送者等待？ │──是──> 直接接收数据
└─────────────────┘
          │ 否
          ▼
   阻塞，挂起接收者，等待发送者出现
```

---

#### 3️⃣ 核心理解

* **无缓冲 channel = 同步 channel**
* 每次发送必须有对应接收，否则 Goroutine 阻塞。
* 因为容量为 0，底层环形队列几乎没有存储作用，主要起到 **协调 Goroutine 阻塞与唤醒** 的角色。
* 发送和接收操作仍然可能 **同时到达同一个 channel**。
* 锁保护 **发送队列和接收队列**，保证两个 Goroutine 可以正确匹配，避免竞争条件。

---

### 3️⃣ 总结锁的作用

| 场景              | 锁保护对象                 | 作用                                 |
| --------------- | --------------------- | ---------------------------------- |
| **发送者写缓冲**      | 环形队列                  | 保证同一时刻只有一个 Goroutine 写入队列，防止数据覆盖   |
| **接收者读缓冲**      | 环形队列                  | 保证同一时刻只有一个 Goroutine 读队列，防止重复或丢失数据 |
| **挂起/唤醒**       | sendQueue / recvQueue | 保证等待队列的 Goroutine 添加、移除、唤醒操作安全     |
| **无缓冲 channel** | sendQueue / recvQueue | 保证发送者与接收者正确匹配，不会出现错乱或丢失数据          |

---

✅ **核心理解**：

> 锁不是保护某个 Goroutine，而是保护 **channel 的共享状态**，包括缓冲区、发送/接收队列，以及阻塞挂起与唤醒操作。

#### Channel 常见应用模式

1. **Worker Pool（并发任务池）**
   用 channel 分发任务，worker 并发处理，提高 CPU 利用率。
2. **Fan-out**
   一个输入 channel，多个 goroutine 并发消费。
3. **Fan-in**
   多个 channel 合并成一个输出 channel，统一处理结果。
4. **超时控制**
   `select { case <-ch: … case <-time.After(d): … }` 避免 goroutine 永远阻塞。
